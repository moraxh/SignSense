{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad3c1d06",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bccab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d9eb4f",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b9736",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = \"./cache\"\n",
    "DATASET_DIR = \"./dataset\" \n",
    "\n",
    "DATASET_FILE = f\"{CACHE_DIR}/dataset.csv\"\n",
    "\n",
    "LANDMARKS_PAIRS = [\n",
    "    # Tip-to-tip (neighboring fingers)\n",
    "    (4, 8), (8, 12), (12, 16), (16, 20),\n",
    "\n",
    "    # Wrist to each fingertip\n",
    "    (0, 4), (0, 8), (0, 12), (0, 16), (0, 20),\n",
    "\n",
    "    # Tip to base of the same finger (to capture bending)\n",
    "    (4, 3), (8, 6), (12, 10), (16, 14), (20, 18),\n",
    "\n",
    "    # Thumb to other fingertips (e.g., letters like G, L)\n",
    "    (4, 12), (4, 16), (4, 20),\n",
    "\n",
    "    # Palm width: base-to-base\n",
    "    (5, 17), (2, 20)\n",
    "]\n",
    "LANDMARKS_TRIPLETS = [\n",
    "    # Index finger\n",
    "    (5, 6, 7), (6, 7, 8),\n",
    "\n",
    "    # Middle finger\n",
    "    (9, 10, 11), (10, 11, 12),\n",
    "\n",
    "    # Ring finger\n",
    "    (13, 14, 15), (14, 15, 16),\n",
    "\n",
    "    # Pinky finger\n",
    "    (17, 18, 19), (18, 19, 20),\n",
    "\n",
    "    # Thumb\n",
    "    (1, 2, 3), (2, 3, 4),\n",
    "\n",
    "    # Palm structure\n",
    "    (0, 5, 9), (0, 9, 13), (0, 13, 17)\n",
    "]\n",
    "LANDMARKS_TIPS = [4, 8, 12, 16, 20]\n",
    "LANDMARKS_PIPS = [3, 6, 10, 14, 18]\n",
    "\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b9feb0",
   "metadata": {},
   "source": [
    "# Initialize mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c3a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1)\n",
    "mp_draw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc37a8c",
   "metadata": {},
   "source": [
    "# Get the coordinates and extract the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e09a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_landmarks(points):\n",
    "  center = points[0]\n",
    "  points = points - center\n",
    "\n",
    "  scale = np.linalg.norm(points[0] - points[9])\n",
    "  if scale != 0:\n",
    "    points = points / scale\n",
    "  \n",
    "  return points\n",
    "\n",
    "def pairwise_distances(landmarks, pairs):\n",
    "  dists = []\n",
    "  for i, j in pairs:\n",
    "    dists.append(np.linalg.norm(landmarks[i] - landmarks[j]))\n",
    "  return np.array(dists)\n",
    "\n",
    "def angles(landmarks, triples):\n",
    "  angs = []\n",
    "  for i, j, k in triples:\n",
    "    v1 = landmarks[i] - landmarks[j]\n",
    "    v2 = landmarks[k] - landmarks[j]\n",
    "    # cosθ = (v1·v2) / (‖v1‖‖v2‖)\n",
    "    cosang = np.dot(v1, v2) / (np.linalg.norm(v1)*np.linalg.norm(v2) + 1e-8)\n",
    "    θ = np.degrees(np.arccos(np.clip(cosang, -1, 1)))\n",
    "    angs.append(θ)\n",
    "  return np.array(angs)\n",
    "\n",
    "def convex_hull_area(landmarks):\n",
    "  hull = ConvexHull(landmarks)\n",
    "  return hull.area\n",
    "\n",
    "def count_extended_fingers(landmarks, finger_tips, finger_pips):\n",
    "  wrist = landmarks[0]\n",
    "  count = 0\n",
    "  for tip, pip in zip(finger_tips, finger_pips):\n",
    "    d_tip = np.linalg.norm(landmarks[tip] - wrist)\n",
    "    d_pip = np.linalg.norm(landmarks[pip] - wrist)\n",
    "    if d_tip > d_pip:\n",
    "      count += 1\n",
    "  return count\n",
    "\n",
    "def bounding_box_features(landmarks):\n",
    "  x = [pt[0] for pt in landmarks]\n",
    "  y = [pt[1] for pt in landmarks]\n",
    "  width = max(x) - min(x)\n",
    "  height = max(y) - min(y)\n",
    "  aspect_ratio = width / (height + 1e-6)\n",
    "  return width, height, aspect_ratio\n",
    "\n",
    "def hand_orientation_angle(landmarks):\n",
    "  wrist = np.array(landmarks[0])\n",
    "  middle_base = np.array(landmarks[9])\n",
    "  vec = middle_base - wrist\n",
    "  angle = np.arctan2(vec[1], vec[0])\n",
    "  return angle\n",
    "\n",
    "def create_dataset():\n",
    "  data = []\n",
    "\n",
    "  for label in tqdm(os.listdir(DATASET_DIR), desc=\"Reading and extracting\", unit=\"label\"):\n",
    "    label_path = os.path.join(DATASET_DIR, label)\n",
    "    for image in os.listdir(label_path):\n",
    "      image_path = os.path.join(label_path, image)\n",
    "\n",
    "      img = cv2.imread(image_path)\n",
    "      img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "      results = hands.process(img_rgb)\n",
    "\n",
    "      if not results.multi_hand_landmarks:\n",
    "        print(f\"Warning: No hand landmarks found in {image_path}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "      for hand in results.multi_hand_landmarks:\n",
    "        h, w, _ = img.shape\n",
    "        points = []\n",
    "        for lm in hand.landmark:\n",
    "          x = lm.x * w\n",
    "          y = lm.y * h\n",
    "          points.append([x, y])\n",
    "        \n",
    "        points = np.array(points)\n",
    "\n",
    "        points = normalize_landmarks(points)\n",
    "\n",
    "        dist_feats = pairwise_distances(points, LANDMARKS_PAIRS)\n",
    "        ang_feats = angles(points, LANDMARKS_TRIPLETS)\n",
    "        area = convex_hull_area(points)\n",
    "        angle = hand_orientation_angle(points)\n",
    "        n_extended = count_extended_fingers(points, LANDMARKS_TIPS, LANDMARKS_PIPS)\n",
    "        width, height, aspect_ratio = bounding_box_features(points)\n",
    "\n",
    "        sample = { \"label\": label }\n",
    "\n",
    "        for i, val in enumerate(dist_feats):\n",
    "          sample[f\"dist_{i}\"] = val\n",
    "        \n",
    "        for i, val in enumerate(ang_feats):\n",
    "          sample[f\"ang_{i}\"] = val\n",
    "\n",
    "        sample[\"area\"] = area\n",
    "        sample[\"angle\"] = angle\n",
    "        sample[\"width\"] = width\n",
    "        sample[\"height\"] = height\n",
    "        sample[\"aspect_ratio\"] = aspect_ratio\n",
    "        sample[\"n_extended\"] = n_extended\n",
    "\n",
    "        data.append(sample)\n",
    "\n",
    "  df = pd.DataFrame(data)\n",
    "  df.to_csv(DATASET_FILE, index=False)\n",
    "    \n",
    "if not os.path.exists(DATASET_FILE):\n",
    "  print(\"Not found dataset file, creating...\")\n",
    "  create_dataset()\n",
    "else:\n",
    "  print(\"Dataset file found, loading...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c63726",
   "metadata": {},
   "source": [
    "# Try to predict with models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_FILE)\n",
    "\n",
    "X = df.drop(columns=[\"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Codificar etiquetas\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "class_names = le.classes_\n",
    "n_classes = len(class_names)\n",
    "\n",
    "# Binarizar etiquetas para ROC multiclase\n",
    "y_binarized = label_binarize(y_encoded, classes=range(n_classes))\n",
    "\n",
    "# Dividir datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "y_test_binarized = label_binarize(y_test, classes=range(n_classes))\n",
    "\n",
    "# Modelos\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=5000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=6),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='mlogloss', use_label_encoder=False)\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "\n",
    "# Entrenar y evaluar\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🔍 Evaluando: {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    probas = model.predict_proba(X_test)\n",
    "\n",
    "    # Accuracy y reporte\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc\n",
    "        best_model = name\n",
    "\n",
    "    print(f\"📊 Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, preds, target_names=class_names))\n",
    "\n",
    "    # Matriz de confusión\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.title(f\"{name} - Matriz de Confusión (27 clases)\")\n",
    "    plt.xlabel(\"Predicho\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curves\n",
    "    fpr_micro, tpr_micro, _ = roc_curve(y_test_binarized.ravel(), probas.ravel())\n",
    "    roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr_micro, tpr_micro, label=f\"Micro-average ROC (AUC = {roc_auc_micro:.2f})\", color='blue')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    plt.title(f\"{name} - ROC Micro-average\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f19cf3b",
   "metadata": {},
   "source": [
    "# Predict with WebCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5262933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "  raise \"The camera couldn't be open\"\n",
    "\n",
    "while True:\n",
    "  ret, frame = cap.read()\n",
    "  if not ret:\n",
    "    print(\"Frame Error\")\n",
    "    break\n",
    "\n",
    "  rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "  results = hands.process(rgb_frame)\n",
    "\n",
    "  if results.multi_hand_landmarks:\n",
    "    for hand in results.multi_hand_landmarks:\n",
    "      mp_draw.draw_landmarks(frame, hand, mp_hands.HAND_CONNECTIONS)\n",
    "      h, w, _ = frame.shape\n",
    "      points = []\n",
    "      for lm in hand.landmark:\n",
    "        x = lm.x * w\n",
    "        y = lm.y * h\n",
    "        points.append([x, y])\n",
    "\n",
    "      points = np.array(points)\n",
    "\n",
    "      points = normalize_landmarks(points)\n",
    "      dist_feats = pairwise_distances(points, LANDMARKS_PAIRS)\n",
    "      ang_feats = angles(points, LANDMARKS_TRIPLETS)\n",
    "      area = convex_hull_area(points)\n",
    "      angle = hand_orientation_angle(points)\n",
    "      n_extended = count_extended_fingers(points, LANDMARKS_TIPS, LANDMARKS_PIPS)\n",
    "      width, height, aspect_ratio = bounding_box_features(points)\n",
    "\n",
    "      sample = { }\n",
    "\n",
    "      for i, val in enumerate(dist_feats):\n",
    "        sample[f\"dist_{i}\"] = val\n",
    "      \n",
    "      for i, val in enumerate(ang_feats):\n",
    "        sample[f\"ang_{i}\"] = val\n",
    "\n",
    "      sample[\"area\"] = area\n",
    "      sample[\"angle\"] = angle\n",
    "      sample[\"width\"] = width\n",
    "      sample[\"height\"] = height\n",
    "      sample[\"aspect_ratio\"] = aspect_ratio\n",
    "      sample[\"n_extended\"] = n_extended\n",
    "      \n",
    "      sample_df = pd.DataFrame([sample])\n",
    "      sample_df = sample_df.reindex(columns=X.columns, fill_value=0)\n",
    "      pred = models[best_model].predict(sample_df)[0]\n",
    "      pred_label = le.inverse_transform([pred])[0]\n",
    "      cv2.putText(frame, f\"Predicted: {pred_label}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "  cv2.imshow('Webcam with Hand Landmarks', frame)\n",
    "\n",
    "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
